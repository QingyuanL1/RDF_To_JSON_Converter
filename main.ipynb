{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 151\u001b[0m\n\u001b[1;32m    148\u001b[0m df_classes_sorted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuperclasses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_classes_sorted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuperclasses\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(flatten_field)\n\u001b[1;32m    149\u001b[0m df_classes_sorted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEquivalentClasses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_classes_sorted\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEquivalentClasses\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(flatten_field)\n\u001b[0;32m--> 151\u001b[0m df_classes_sorted\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# For JSON, save as is\u001b[39;00m\n\u001b[1;32m    154\u001b[0m df_classes_sorted\u001b[38;5;241m.\u001b[39mto_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/classes.json\u001b[39m\u001b[38;5;124m'\u001b[39m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m, force_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3903\u001b[0m     path_or_buf,\n\u001b[1;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3919\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[1;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[1;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[1;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from rdflib import Graph, URIRef, RDFS, RDF, OWL, Literal, BNode\n",
    "\n",
    "def get_local_name(uri):\n",
    "    if '#' in uri:\n",
    "        return uri.split('#')[-1]\n",
    "    else:\n",
    "        return uri.rsplit('/', 1)[-1]\n",
    "\n",
    "def is_valid_label(label):\n",
    "    if len(label) >= 32 and re.match(r'^[A-Za-z0-9]+$', label):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def literal_to_string(literal):\n",
    "    if isinstance(literal, Literal):\n",
    "        return str(literal.value)\n",
    "    else:\n",
    "        return str(literal)\n",
    "\n",
    "def process_anonymous_class(bnode, graph):\n",
    "    # This function processes an anonymous class and returns a description of it\n",
    "    anon_class_info = {}\n",
    "    for p, o in graph.predicate_objects(bnode):\n",
    "        if p == OWL.onProperty:\n",
    "            anon_class_info['onProperty'] = str(o)\n",
    "        elif p == OWL.someValuesFrom:\n",
    "            anon_class_info['someValuesFrom'] = str(o)\n",
    "        elif p == OWL.allValuesFrom:\n",
    "            anon_class_info['allValuesFrom'] = str(o)\n",
    "        elif p == OWL.onClass:\n",
    "            anon_class_info['onClass'] = str(o)\n",
    "        elif p == OWL.qualifiedCardinality:\n",
    "            anon_class_info['qualifiedCardinality'] = str(o)\n",
    "        elif p == OWL.intersectionOf:\n",
    "            # Handle intersectionOf\n",
    "            anon_class_info['intersectionOf'] = []\n",
    "            for item in graph.items(o):\n",
    "                if isinstance(item, URIRef):\n",
    "                    anon_class_info['intersectionOf'].append(str(item))\n",
    "                elif isinstance(item, BNode):\n",
    "                    anon_class_info['intersectionOf'].append(process_anonymous_class(item, graph))\n",
    "        elif p == RDF.type:\n",
    "            # skip type\n",
    "            pass\n",
    "        else:\n",
    "            # other properties\n",
    "            anon_class_info[str(p)] = str(o)\n",
    "    return anon_class_info\n",
    "\n",
    "def process_class(s, graph):\n",
    "    class_info = {'URI': str(s)}\n",
    "    \n",
    "    # Get label\n",
    "    labels = list(graph.objects(s, RDFS.label))\n",
    "    if labels:\n",
    "        label_str = literal_to_string(labels[0])\n",
    "        if not is_valid_label(label_str):\n",
    "            label_str = get_local_name(str(s))\n",
    "    else:\n",
    "        label_str = get_local_name(str(s))\n",
    "    class_info['Label'] = label_str\n",
    "\n",
    "    # Get comment\n",
    "    comments = list(graph.objects(s, RDFS.comment))\n",
    "    if comments:\n",
    "        comment_str = ' '.join([literal_to_string(c) for c in comments])\n",
    "        class_info['Comment'] = comment_str\n",
    "    else:\n",
    "        class_info['Comment'] = ''\n",
    "\n",
    "    # Get superclasses\n",
    "    superclasses = []\n",
    "    for o in graph.objects(s, RDFS.subClassOf):\n",
    "        if isinstance(o, URIRef):\n",
    "            superclasses.append(str(o))\n",
    "        elif isinstance(o, BNode):\n",
    "            superclasses.append(process_anonymous_class(o, graph))\n",
    "        else:\n",
    "            superclasses.append(\"[Unknown superclass type]\")\n",
    "    class_info['Superclasses'] = superclasses\n",
    "\n",
    "    # Get equivalent classes\n",
    "    equivalent_classes = []\n",
    "    for o in graph.objects(s, OWL.equivalentClass):\n",
    "        if isinstance(o, URIRef):\n",
    "            equivalent_classes.append(str(o))\n",
    "        elif isinstance(o, BNode):\n",
    "            equivalent_classes.append(process_anonymous_class(o, graph))\n",
    "        else:\n",
    "            equivalent_classes.append(\"[Unknown equivalent class type]\")\n",
    "    if equivalent_classes:\n",
    "        class_info['EquivalentClasses'] = equivalent_classes\n",
    "\n",
    "    # Optionally, process other attributes here\n",
    "\n",
    "    return class_info\n",
    "\n",
    "rdf_file_path = 'BEO (Building Energy Ontology).rdf'\n",
    "g = Graph()\n",
    "g.parse(rdf_file_path, format=\"xml\")\n",
    "\n",
    "excluded_classes = [\n",
    "    \"http://www.w3.org/2002/07/owl#Thing\",\n",
    "    \"https://www.auto.tuwien.ac.at/downloads/thinkhome/ontology/EnergyResourceOntology.owl#EnergyConsumerFacility\",\n",
    "    \"http://energy.linkeddata.es/em-kpi/ontology#EnergyConsumer\",\n",
    "    \"http://energy.linkeddata.es/em-kpi/ontology#GeneratingUnit\",\n",
    "    \"http://energy.linkeddata.es/em-kpi/ontology#PowerDeliveryUnit\",\n",
    "    \"http://energy.linkeddata.es/em-kpi/ontology#PowerSystemResource\",\n",
    "    \"https://www.auto.tuwien.ac.at/downloads/thinkhome/ontology/EnergyResourceOntology.owl#EnergyProducerFacility\"\n",
    "]\n",
    "\n",
    "included_classes = [\n",
    "    \"https://saref.etsi.org/core/Measurement\",\n",
    "]\n",
    "\n",
    "class_list = []\n",
    "\n",
    "for s in g.subjects(RDF.type, OWL.Class):\n",
    "    s_str = str(s)\n",
    "    if s_str in excluded_classes:\n",
    "        continue\n",
    "\n",
    "    class_info = process_class(s, g)\n",
    "    class_list.append(class_info)\n",
    "\n",
    "df_classes = pd.DataFrame(class_list)\n",
    "\n",
    "# Sort by label\n",
    "df_classes_sorted = df_classes.sort_values(by=[\"Label\"])\n",
    "\n",
    "pattern = r'^N[0-9a-f]{32}$'\n",
    "\n",
    "# Filter out the rows where 'Label' matches the pattern\n",
    "df_classes_sorted = df_classes_sorted[\n",
    "    ~df_classes_sorted['Label'].str.match(pattern)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# For CSV, flatten the complex fields\n",
    "def flatten_field(field):\n",
    "    if isinstance(field, list):\n",
    "        return json.dumps(field, ensure_ascii=False)\n",
    "    else:\n",
    "        return field\n",
    "\n",
    "df_classes_sorted['Superclasses'] = df_classes_sorted['Superclasses'].apply(flatten_field)\n",
    "df_classes_sorted['EquivalentClasses'] = df_classes_sorted.get('EquivalentClasses', '').apply(flatten_field)\n",
    "\n",
    "df_classes_sorted.to_csv('results/data.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# For JSON, save as is\n",
    "df_classes_sorted.to_json('results/classes.json', orient='records', force_ascii=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
